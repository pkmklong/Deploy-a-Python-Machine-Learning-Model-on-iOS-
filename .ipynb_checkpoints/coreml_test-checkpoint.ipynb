{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install scikit-learn==0.19.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.19.2'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn as sk\n",
    "sk.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:17: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import Mapping, defaultdict\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "import pandas as pd\n",
    "from sklearn.model_selection  import train_test_split\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "import coremltools as cml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston = load_boston()\n",
    "boston_df = pd.DataFrame(boston['data'] )\n",
    "boston_df.columns = boston['feature_names']\n",
    "boston_df['PRICE']= boston['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX',\n",
       "       'PTRATIO', 'B', 'LSTAT', 'PRICE'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston = load_boston()\n",
    "boston_df = pd.DataFrame(boston['data'] )\n",
    "boston_df.columns = boston['feature_names']\n",
    "boston_df['PRICE']= boston['target']\n",
    "\n",
    "y = boston_df['PRICE']\n",
    "X = boston_df.loc[:,[\"RM\", \"AGE\", \"PTRATIO\"]]\n",
    "\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "train_test_split(X, y, test_size=0.3, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm = LinearRegression()\n",
    "lm.fit( X_train, y_train )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 6.416, 84.1  , 16.6  ])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.iloc[0,:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([24.64960146])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.predict(X_test.iloc[0,:].values.reshape(1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "coreml_model = cml.converters.sklearn.convert(lm,[\"RM\", \"AGE\", \"PTRATIO\"], \"PRICE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set model metadata\n",
    "coreml_model.author = 'Patrick Long'\n",
    "coreml_model.license = 'MIT'\n",
    "coreml_model.short_description = 'Predicts the price of a house in Boston'\n",
    "\n",
    "# Set feature descriptions manually\n",
    "coreml_model.input_description['RM'] = 'Number of bedrooms'\n",
    "coreml_model.input_description['AGE'] = 'Age of house (in years)'\n",
    "coreml_model.input_description['PTRATIO'] = 'pupil-teacher ratio by town'\n",
    "\n",
    "# Set the output descriptions\n",
    "coreml_model.output_description['PRICE'] = 'Price of the house (1k USD)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "coreml_model.save('bhousing.mlmodel')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pytorch Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.utils import shuffle\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train=X_train.values\n",
    "# y_train=y_train.values\n",
    "# X_test=X_test.values\n",
    "# y_test=y_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/torch/nn/_reduction.py:43: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    }
   ],
   "source": [
    "batch_size = 50\n",
    "num_epochs = 200\n",
    "learning_rate = 0.01\n",
    "size_hidden= 100\n",
    "\n",
    "batch_no = len(X_train) // batch_size\n",
    "cols=X_train.shape[1]\n",
    "n_output=1\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, n_feature, size_hidden, n_output):\n",
    "        super(Net, self).__init__()\n",
    "        self.hidden = torch.nn.Linear(cols, size_hidden)\n",
    "        self.predict = torch.nn.Linear(size_hidden, n_output)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.hidden(x))      \n",
    "        x = self.predict(x)             \n",
    "        return x\n",
    "    \n",
    "net = Net(cols, size_hidden, n_output)\n",
    "\n",
    "\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)\n",
    "criterion = torch.nn.MSELoss(size_average=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 loss: 90235.0947265625\n",
      "Epoch 2 loss: 69497.4794921875\n",
      "Epoch 3 loss: 52912.38720703125\n",
      "Epoch 4 loss: 39093.61474609375\n",
      "Epoch 5 loss: 25986.491821289062\n",
      "Epoch 6 loss: 19522.440795898438\n",
      "Epoch 7 loss: 19685.345458984375\n",
      "Epoch 8 loss: 19210.970947265625\n",
      "Epoch 9 loss: 24234.268310546875\n",
      "Epoch 10 loss: 22860.192626953125\n",
      "Epoch 11 loss: 22322.123291015625\n",
      "Epoch 12 loss: 20221.342041015625\n",
      "Epoch 13 loss: 18484.729125976562\n",
      "Epoch 14 loss: 16450.033447265625\n",
      "Epoch 15 loss: 15676.039916992188\n",
      "Epoch 16 loss: 15577.183715820312\n",
      "Epoch 17 loss: 15555.283447265625\n",
      "Epoch 18 loss: 15681.602416992188\n",
      "Epoch 19 loss: 15635.83251953125\n",
      "Epoch 20 loss: 15438.21630859375\n",
      "Epoch 21 loss: 15614.758178710938\n",
      "Epoch 22 loss: 15385.40576171875\n",
      "Epoch 23 loss: 16660.434692382812\n",
      "Epoch 24 loss: 15968.224853515625\n",
      "Epoch 25 loss: 15542.061401367188\n",
      "Epoch 26 loss: 16601.08251953125\n",
      "Epoch 27 loss: 15449.7392578125\n",
      "Epoch 28 loss: 15704.63427734375\n",
      "Epoch 29 loss: 15885.902709960938\n",
      "Epoch 30 loss: 14921.618408203125\n",
      "Epoch 31 loss: 16043.181274414062\n",
      "Epoch 32 loss: 15290.82958984375\n",
      "Epoch 33 loss: 15044.945434570312\n",
      "Epoch 34 loss: 15188.585815429688\n",
      "Epoch 35 loss: 15127.427734375\n",
      "Epoch 36 loss: 14814.945068359375\n",
      "Epoch 37 loss: 15126.6923828125\n",
      "Epoch 38 loss: 15557.023193359375\n",
      "Epoch 39 loss: 16337.545654296875\n",
      "Epoch 40 loss: 15494.437255859375\n",
      "Epoch 41 loss: 14499.671875\n",
      "Epoch 42 loss: 15370.75\n",
      "Epoch 43 loss: 15545.800415039062\n",
      "Epoch 44 loss: 16143.429565429688\n",
      "Epoch 45 loss: 16824.06671142578\n",
      "Epoch 46 loss: 14749.865112304688\n",
      "Epoch 47 loss: 14376.348937988281\n",
      "Epoch 48 loss: 14251.370483398438\n",
      "Epoch 49 loss: 16245.81884765625\n",
      "Epoch 50 loss: 17282.504150390625\n",
      "Epoch 51 loss: 19855.2451171875\n",
      "Epoch 52 loss: 16721.000732421875\n",
      "Epoch 53 loss: 14743.964599609375\n",
      "Epoch 54 loss: 16604.599609375\n",
      "Epoch 55 loss: 16556.3544921875\n",
      "Epoch 56 loss: 15310.3525390625\n",
      "Epoch 57 loss: 14722.257080078125\n",
      "Epoch 58 loss: 14597.649169921875\n",
      "Epoch 59 loss: 15179.713134765625\n",
      "Epoch 60 loss: 14374.305053710938\n",
      "Epoch 61 loss: 14459.827392578125\n",
      "Epoch 62 loss: 14491.875122070312\n",
      "Epoch 63 loss: 15930.9091796875\n",
      "Epoch 64 loss: 15878.318359375\n",
      "Epoch 65 loss: 16747.679565429688\n",
      "Epoch 66 loss: 17410.637817382812\n",
      "Epoch 67 loss: 13823.986328125\n",
      "Epoch 68 loss: 13968.540649414062\n",
      "Epoch 69 loss: 13729.12158203125\n",
      "Epoch 70 loss: 14318.73876953125\n",
      "Epoch 71 loss: 14855.665100097656\n",
      "Epoch 72 loss: 15285.040771484375\n",
      "Epoch 73 loss: 13994.628662109375\n",
      "Epoch 74 loss: 15002.94921875\n",
      "Epoch 75 loss: 14634.28662109375\n",
      "Epoch 76 loss: 15483.809936523438\n",
      "Epoch 77 loss: 14378.684204101562\n",
      "Epoch 78 loss: 16650.865234375\n",
      "Epoch 79 loss: 15614.37109375\n",
      "Epoch 80 loss: 16906.92724609375\n",
      "Epoch 81 loss: 18082.836547851562\n",
      "Epoch 82 loss: 15239.411254882812\n",
      "Epoch 83 loss: 14335.682495117188\n",
      "Epoch 84 loss: 15330.359008789062\n",
      "Epoch 85 loss: 15759.00927734375\n",
      "Epoch 86 loss: 16470.618286132812\n",
      "Epoch 87 loss: 15501.4609375\n",
      "Epoch 88 loss: 17077.69970703125\n",
      "Epoch 89 loss: 16535.514892578125\n",
      "Epoch 90 loss: 15282.521606445312\n",
      "Epoch 91 loss: 13871.471069335938\n",
      "Epoch 92 loss: 14684.787353515625\n",
      "Epoch 93 loss: 13808.588256835938\n",
      "Epoch 94 loss: 13592.372802734375\n",
      "Epoch 95 loss: 15082.873657226562\n",
      "Epoch 96 loss: 14177.8623046875\n",
      "Epoch 97 loss: 14945.156005859375\n",
      "Epoch 98 loss: 15304.423217773438\n",
      "Epoch 99 loss: 13756.565368652344\n",
      "Epoch 100 loss: 13618.3212890625\n",
      "Epoch 101 loss: 12192.12939453125\n",
      "Epoch 102 loss: 13582.027099609375\n",
      "Epoch 103 loss: 13426.208984375\n",
      "Epoch 104 loss: 13687.421142578125\n",
      "Epoch 105 loss: 13636.060791015625\n",
      "Epoch 106 loss: 13428.178100585938\n",
      "Epoch 107 loss: 15074.828491210938\n",
      "Epoch 108 loss: 12815.416442871094\n",
      "Epoch 109 loss: 14077.701354980469\n",
      "Epoch 110 loss: 13305.259765625\n",
      "Epoch 111 loss: 13333.983825683594\n",
      "Epoch 112 loss: 13758.314453125\n",
      "Epoch 113 loss: 13253.19970703125\n",
      "Epoch 114 loss: 13173.80126953125\n",
      "Epoch 115 loss: 14111.195922851562\n",
      "Epoch 116 loss: 13275.854125976562\n",
      "Epoch 117 loss: 13473.10595703125\n",
      "Epoch 118 loss: 13529.7138671875\n",
      "Epoch 119 loss: 13104.38916015625\n",
      "Epoch 120 loss: 13178.478271484375\n",
      "Epoch 121 loss: 13063.822265625\n",
      "Epoch 122 loss: 13949.642517089844\n",
      "Epoch 123 loss: 15296.1708984375\n",
      "Epoch 124 loss: 14404.745849609375\n",
      "Epoch 125 loss: 16868.3818359375\n",
      "Epoch 126 loss: 13800.734008789062\n",
      "Epoch 127 loss: 15922.244262695312\n",
      "Epoch 128 loss: 16849.53466796875\n",
      "Epoch 129 loss: 14814.278686523438\n",
      "Epoch 130 loss: 14790.958984375\n",
      "Epoch 131 loss: 13234.93115234375\n",
      "Epoch 132 loss: 13931.324951171875\n",
      "Epoch 133 loss: 13928.552978515625\n",
      "Epoch 134 loss: 13410.068359375\n",
      "Epoch 135 loss: 15698.9775390625\n",
      "Epoch 136 loss: 13727.695556640625\n",
      "Epoch 137 loss: 12750.987121582031\n",
      "Epoch 138 loss: 13214.155578613281\n",
      "Epoch 139 loss: 12743.137939453125\n",
      "Epoch 140 loss: 12820.009887695312\n",
      "Epoch 141 loss: 12987.724792480469\n",
      "Epoch 142 loss: 13097.871459960938\n",
      "Epoch 143 loss: 12523.556274414062\n",
      "Epoch 144 loss: 12547.495971679688\n",
      "Epoch 145 loss: 12413.875366210938\n",
      "Epoch 146 loss: 14434.20068359375\n",
      "Epoch 147 loss: 14045.668212890625\n",
      "Epoch 148 loss: 14783.088195800781\n",
      "Epoch 149 loss: 15179.841552734375\n",
      "Epoch 150 loss: 13550.259643554688\n",
      "Epoch 151 loss: 12456.409057617188\n",
      "Epoch 152 loss: 12918.663635253906\n",
      "Epoch 153 loss: 13288.176025390625\n",
      "Epoch 154 loss: 12272.564575195312\n",
      "Epoch 155 loss: 12738.835083007812\n",
      "Epoch 156 loss: 12481.468444824219\n",
      "Epoch 157 loss: 13336.111999511719\n",
      "Epoch 158 loss: 13624.37548828125\n",
      "Epoch 159 loss: 12779.6865234375\n",
      "Epoch 160 loss: 12252.016479492188\n",
      "Epoch 161 loss: 12583.337219238281\n",
      "Epoch 162 loss: 12573.586547851562\n",
      "Epoch 163 loss: 12339.669372558594\n",
      "Epoch 164 loss: 12118.961059570312\n",
      "Epoch 165 loss: 12247.236450195312\n",
      "Epoch 166 loss: 13165.337890625\n",
      "Epoch 167 loss: 12438.71630859375\n",
      "Epoch 168 loss: 12231.401733398438\n",
      "Epoch 169 loss: 12671.878662109375\n",
      "Epoch 170 loss: 13542.798461914062\n",
      "Epoch 171 loss: 12400.739135742188\n",
      "Epoch 172 loss: 13352.794067382812\n",
      "Epoch 173 loss: 13274.114562988281\n",
      "Epoch 174 loss: 12061.172607421875\n",
      "Epoch 175 loss: 12686.352416992188\n",
      "Epoch 176 loss: 13056.512451171875\n",
      "Epoch 177 loss: 13135.567504882812\n",
      "Epoch 178 loss: 12806.238342285156\n",
      "Epoch 179 loss: 13086.49267578125\n",
      "Epoch 180 loss: 12858.435546875\n",
      "Epoch 181 loss: 13276.126953125\n",
      "Epoch 182 loss: 14114.68359375\n",
      "Epoch 183 loss: 14886.956665039062\n",
      "Epoch 184 loss: 13382.446411132812\n",
      "Epoch 185 loss: 13783.039672851562\n",
      "Epoch 186 loss: 13399.9130859375\n",
      "Epoch 187 loss: 12451.947143554688\n",
      "Epoch 188 loss: 12199.984008789062\n",
      "Epoch 189 loss: 13051.810485839844\n",
      "Epoch 190 loss: 11767.565490722656\n",
      "Epoch 191 loss: 11773.2880859375\n",
      "Epoch 192 loss: 12334.170776367188\n",
      "Epoch 193 loss: 12380.642944335938\n",
      "Epoch 194 loss: 11746.652709960938\n",
      "Epoch 195 loss: 12246.100708007812\n",
      "Epoch 196 loss: 12011.015075683594\n",
      "Epoch 197 loss: 13118.052673339844\n",
      "Epoch 198 loss: 12021.044067382812\n",
      "Epoch 199 loss: 11483.697998046875\n",
      "Epoch 200 loss: 12454.587280273438\n"
     ]
    }
   ],
   "source": [
    "running_loss = 0.0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    X_train, y_train = shuffle(X_train, y_train)\n",
    "    for i in range(batch_no):\n",
    "        start = i * batch_size\n",
    "        end = start + batch_size\n",
    "        inputs = Variable(torch.FloatTensor(X_train[start:end]))\n",
    "        labels = Variable(torch.FloatTensor(y_train[start:end]))\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "\n",
    "        loss = criterion(outputs, torch.unsqueeze(labels,dim=1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "    print(f\"Epoch {epoch+1}\", f\"loss: {running_loss}\")\n",
    "    running_loss = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (hidden): Linear(in_features=2, out_features=100, bias=True)\n",
       "  (predict): Linear(in_features=100, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "coreml_model = cml.converters.sklearn.convert(lm,[\"RM\", \"AGE\"], \"PRICE\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.eval()\n",
    "example_input = torch.rand(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "traced_model = torch.jit.trace(net, example_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = cml.TensorType(name='features', shape=(1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torch._C' has no attribute '_jit_pass_lower_graph'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-f1ec7d329329>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmlmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraced_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/coremltools/converters/_converters_entry.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(model, source, inputs, outputs, classifier_config, minimum_deployment_target, convert_to, **kwargs)\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m         \u001b[0mclassifier_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclassifier_config\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m         \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m     )\n\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/coremltools/converters/mil/converter.py\u001b[0m in \u001b[0;36mmil_convert\u001b[0;34m(model, convert_from, convert_to, **kwargs)\u001b[0m\n\u001b[1;32m    127\u001b[0m     \"\"\"\n\u001b[1;32m    128\u001b[0m     proto = mil_convert_to_proto(model, convert_from, convert_to,\n\u001b[0;32m--> 129\u001b[0;31m         ConverterRegistry, **kwargs)\n\u001b[0m\u001b[1;32m    130\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mconvert_to\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'mil'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mproto\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/coremltools/converters/mil/converter.py\u001b[0m in \u001b[0;36mmil_convert_to_proto\u001b[0;34m(model, convert_from, convert_to, converter_registry, **kwargs)\u001b[0m\n\u001b[1;32m    169\u001b[0m     \u001b[0mfrontend_converter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfrontend_converter_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m     \u001b[0mprog\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfrontend_converter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m     \u001b[0mcommon_pass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprog\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/coremltools/converters/mil/converter.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mfrontend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/coremltools/converters/mil/frontend/torch/load.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(model_spec, debug, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"outputs\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0mcut_at_symbols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cut_at_symbols\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m     \u001b[0mconverter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTorchConverter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorchscript\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcut_at_symbols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/coremltools/converters/mil/frontend/torch/converter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, torchscript, inputs, outputs, cut_at_symbols)\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTranscriptionContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m         \u001b[0mraw_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_expand_and_optimize_ir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtorchscript\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m         self.graph = InternalTorchIRGraph(\n\u001b[1;32m    144\u001b[0m             \u001b[0mraw_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcut_at_symbols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/coremltools/converters/mil/frontend/torch/converter.py\u001b[0m in \u001b[0;36m_expand_and_optimize_ir\u001b[0;34m(torchscript)\u001b[0m\n\u001b[1;32m    248\u001b[0m         \u001b[0;31m# not reference into other modules. Params will contain the \"trainable\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;31m# inputs to the graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m         graph, params = _torch._C._jit_pass_lower_graph(\n\u001b[0m\u001b[1;32m    251\u001b[0m             \u001b[0mtorchscript\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorchscript\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_c\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m         )\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'torch._C' has no attribute '_jit_pass_lower_graph'"
     ]
    }
   ],
   "source": [
    "mlmodel = cml.convert(traced_model, inputs=[input])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Could not open requirements file: [Errno 2] No such file or directory: 'pytorch'\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 20.2.2; however, version 20.3.3 is available.\n",
      "You should consider upgrading via the '/Library/Frameworks/Python.framework/Versions/3.7/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pytorch torchvision -c pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "        >>> example_input = torch.rand(1, 3, 256, 256)\n",
    "        >>> traced_model = torch.jit.trace(model, example_input)\n",
    "\n",
    "        >>> input = ct.TensorType(name='input_name', shape=(1, 3, 256, 256))\n",
    "        >>> mlmodel = ct.convert(traced_model, inputs=[input])\n",
    "        >>> results = mlmodel.predict({\"input\": example_input.numpy()})\n",
    "        >>> print(results['1651']) # 1651 is the node name given by PyTorch's JIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unknown type <class 'str'> for flattening into InputType.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-ecf40382247f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0msource\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"pytorch\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"RM\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"AGE\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m )\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/coremltools/converters/_converters_entry.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(model, source, inputs, outputs, classifier_config, minimum_deployment_target, convert_to, **kwargs)\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[0mexact_source\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_determine_source\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m     _validate_inputs(model, exact_source, inputs, outputs, classifier_config,\n\u001b[0;32m--> 174\u001b[0;31m         **kwargs)\n\u001b[0m\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m     mlmodel = mil_convert(\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/coremltools/converters/_converters_entry.py\u001b[0m in \u001b[0;36m_validate_inputs\u001b[0;34m(model, exact_source, inputs, outputs, classifier_config, **kwargs)\u001b[0m\n\u001b[1;32m    277\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 279\u001b[0;31m         \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_flatten_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    280\u001b[0m         \u001b[0mraise_if_duplicated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m         if inputs is not None and not all(\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/coremltools/converters/_converters_entry.py\u001b[0m in \u001b[0;36m_flatten_list\u001b[0;34m(_inputs)\u001b[0m\n\u001b[1;32m    266\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0m_input\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_inputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m                     \u001b[0mret\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_flatten_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mInputType\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m                     \u001b[0mret\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/coremltools/converters/_converters_entry.py\u001b[0m in \u001b[0;36m_flatten_list\u001b[0;34m(_inputs)\u001b[0m\n\u001b[1;32m    272\u001b[0m                     raise ValueError(\n\u001b[1;32m    273\u001b[0m                         \"Unknown type {} for flattening into InputType.\".format(\n\u001b[0;32m--> 274\u001b[0;31m                             \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    275\u001b[0m                         )\n\u001b[1;32m    276\u001b[0m                     )\n",
      "\u001b[0;31mValueError\u001b[0m: Unknown type <class 'str'> for flattening into InputType."
     ]
    }
   ],
   "source": [
    "model = cml.convert(\n",
    "    net,\n",
    "    source = \"pytorch\",\n",
    "    inputs=[[\"RM\", \"AGE\"]], \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pytorch:\n",
    "\n",
    "        >>> model = torchvision.models.mobilenet_v2()\n",
    "        >>> model.eval()\n",
    "        >>> example_input = torch.rand(1, 3, 256, 256)\n",
    "        >>> traced_model = torch.jit.trace(model, example_input)\n",
    "\n",
    "        >>> input = ct.TensorType(name='input_name', shape=(1, 3, 256, 256))\n",
    "        >>> mlmodel = ct.convert(traced_model, inputs=[input])\n",
    "        >>> results = mlmodel.predict({\"input\": example_input.numpy()})\n",
    "        >>> print(results['1651']) # 1651 is the node name given by PyTorch's JIT"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ioscoreml",
   "language": "python",
   "name": "ioscoreml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
